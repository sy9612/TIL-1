0928

---

# 빅데이터

- PB 정도의 데이터 == 빅데이터
- PB 데이터를 어떻게 머신러닝(처리) 할 것인가?
- 빅데이터 != Data Warehouse

## Hadoop

### 개요

:star: 분산 병렬 프레임워크

> 분산: HDFS 데이터 분산 저장
>
> 데이터 처리 방식: MapReduce

- 대용량 데이터 **분산 처리** 소프트웨어

- 빅데이터 핵심 기술(이었다)

- 플랫폼

- 왜?

  > 1. 대규모 데이터 등장
  >
  > 2. 하드디스크 저장 용량 발전
  >
  >    저장 용량: 1000배 증가
  >
  >    램에 올리는 속도는 25배 증가
  >
  >    --> 저장을 해도 CPU에서 계산이 불가능(읽기 능력 부족)
  >
  >    > Main Memory 등장(RAM 증가)
  >    >
  >    > - 비쌈
  >    > - 많은 양의 데이터를 모두 감당 불가
  >
  > 3. Scale-out 방법론의 등장
  >
  >    >  <-> Scale-up: 크기 증가 (i3 -> i5 -> i7 ...)
  >    >
  >    > 비선형 증가
  >
  >    병렬로 연결하여 컴퓨팅파워 증가
  >
  >    **장점**
  >
  >    - 비용효율적
  >
  >    - 고가용성
  >
  >    - 데이터 분산
  >
  >      ​					ㅁ (Master main node)
  >
  >      ㅁ	ㅁ	ㅁ	ㅁ	ㅁ	ㅁ
  >
  >      A	  B	 C	  C	 B	  A
  >
  >      C	  A	 B	  A	 C	  B
  >
  >      --> 데이터를 잃어버리지 않도록 여러 개의 node에 데이터 분산
  >
  >    **단점**
  >
  >    - 네트워크 코스트 발생
  >
  >      > 노드가 많이 붙을수록 네트워크 비용 증가
  >
  >    - SOPF: 중앙 노드가 응답이 없을 때 시스템이 무너짐
  >
  >    - 데이터 유실
  >    - 저장공간이 많이 필요함

- Hadoop = HDFS(Haddop Distributed File System) + MapReduce

  - 데이터 분산 저장 아키텍처
  - 한 번 저장한 데이터는 수정 할 수없고, 읽기만 가능하게 해서 데이터 무결성 유지

- MapReduce

  - 기존 데이터 처리 방식

    - 가져옴(Fetch) :arrow_right: 처리(Process) :arrow_right: 저장(Save)

      > Fetch 과정에서 많은 Cost 유발

    - Mapper 우선 처리

      > 시간이 남음
      >
      > Mppaer와 Reduce는 동시에 불가능 > 자원 낭비

    -> Map 단계에서 Mapper가 데이터가 저장되어 있는 로컬로 직접 이동 처리하여 기존의 처리  방식에서 발생하는 Cost 문제 해결

  - 현재 처리 방식

    Input :arrow_right: Spliting :arrow_right: Mapping :arrow_right: Shuffling :arrow_right: Reducing :arrow_right: Final result

    :red_circle: Reducing

    > Mapper의 데이터들을 정리

### 단점

- 트랜드와 맞지 않음

  > 머신 러닝에 대해 적절하지 않음

- ML 병목구간 발생

  > 머신러닝은 데이터를 반복적으로 읽어야 함

- 어려운 코딩과 낮은 생산성

  > Spark Scala 언어로 개발 생산성 증가

## Spark

### 개요

- In - Memory processing

  > 훈련에 필요한 데이터를 RAM에 올려놓고 반복적으로 접근
  >
  > - 하드디스크의 데이터를 최대한 RAM에 올려서 사용
  > - RAM: 휘발성, 연산을 처음부터 다시해야 함
  >
  > HDFS 접근 코스트가 없어짐
  >
  > Fault-Tolerant한 램 스토리지를 만들기 위해 훈련 중간 결과를 복사

- 메모리를 활용한 머신러닝 모델 훈련

- HDFS에 반복적으로 접근 필요X

### RDD

Resilient Distributed Datasets: 변형 불가능한 분산된 데이터 셋

> 부서지지 않는 스토리지
>
> - **Lineage**를 통해 분산된 RDD를 만듦
>
>   > 부서질 경우 부서진 RDD를 만들었던 다른 RDD의 여러 개를 가져옴

- Immutable

  RDD 수정 불가

  스토리지 :arrow_right: RDD, RDD :arrow_right: RDD로만 가능

  Read-only

- Transformations & Actions

  명령어 2개만 존재

  - Transformations: RDD를 어떻게 변형할 것인가
  - Actions: RDD 변형 실행

  :star: HDFS의 구조 때문에

  > A를 만들기 위해 1, 2, 3이 필요할 때, 데이터가 분산되어서 저장되어 있으면 네트워크 비용 필요
  >
  > :o: **Lazy-Execution**: 미리 연산 계획을 세워둔 후 연산 시 비용 최소화

- fault-tolerant

  이전 RDD를 통해 유실된 RDD 복구

- DAG?

## 머신러닝

- 지도 학습
- 비지도 학습
- 강화 학습

# AWS Cloud Managed Service

### 프로젝트 역할 및 R&R 개요

1. PM

   > 모든 관리 업무를 책임

2. PL

3. PE or SE

### CMS 역할 및 범위

- CMS 운영 환경에 대한 이해도 확보를 위해 각 커뮤니케이션 채널 별로 전담 인력을 배치하여 원활한 커뮤니케이션과 맞춤형 서비스 구현

- 클라우드 라이프 사이클에서 계획 영역을 제외한 전 영역 지원

  >  계획 :point_right: 클라우드 아키텍처 :point_right: 클라우드 운영 :point_right: 클라우드 최적화 :point_right: 클라우드 신기술 지원(k8s, Serverless, DevOps, New feature 등) :point_right: 클라우드 교육 :point_right: 클라우드 보안관리 :point_right: 클라우드 DB 관리 :point_right: 클라우드 APP 관리

- IaaS 및 PaaS 영역 모니터링 및 운영 업무 수행
  
  - Solution Architect, DBA, Developer, 보안 엔지니어

### 운영 업무 상세 내역

- 매니지드 서비스는 기업의 클라우드 인프라와 클라우드 기반의 시스템을 운영 및 관리하는 IT 운영 서비스로 전통적인 IT 인프라(IaaS) 관리에서 클라우드 전 영역(PaaS, SaaS) 관리로 진화

  - 클라우드 인프라 운영 서비스 정의

  - 클라우드 DB 운영 서비스 정의

    DMS

    - 전문성, 안정성, 효율성, 비용절감, 가용성, 보안성

  - 클라우드 보안 서비스 정의

    MSSP

### 운영 서비스를 위한 관리 툴

##### OpsNow

클라우드 자원 및 비용을 통합, 관리, 신속한 장애 대응 및 안정적인 서비스를 위한 모니터링 지원 자동화 클라우드 관리 플랫폼

- Asset Management
- Cost Management
- AlerNow
- Governance
- Monitoring Dashboard

##### NewRelic

아모레퍼시픽 요구사항을 위한 플랫폼

##### InterMax

비즈니스 서비스 환경에서 end to end 성능 관리 목적 WAS ~ TP ~ DB 통합 성능 관리현황 파악, 이상 감리, 원인 파악, 상세 분석 등

##### AP 장애관리

운영 환경에 대한 모니터링 및 장애에 대한 체계적인 관리를 통하여 즉시 조치하고 재발 방지 계획을 수립, 운영

## AP Sales Legacy Transformation Cloud Infra

### 사업 배경 및 목적

최적화된 Cloud Infra 환경 구성 목적

- 서비스 도메인
- 영업 판매 서비스 도메인
- 영업 공통 서비스 도메인

AWS 클라우드 인프라를 바탕으로 최적의 서비스 환경 구성, 비용효율적인 고수준의 시스템을 빠르게 전개 -> AP SLT 서비스의 경쟁력 강화

- 가용성, 확장성, 비용 최적화, 보안성, 관리용이성

### 사업 방향성 및 전략

- AWS 장점 활용
- 클라우드를 위한 ITIL과 마찬가지로 AWS Serverless는 프로그래밍 방식 인터페이스와 AWS 전문 기술의 고유한 조합을 통해 운영 구조 및 제어 기능 제공
- 탄력적으로 리스소 사용 가능 -> 비즈니스 집중

- 가용 영역
  - 2개 이상의 AZ 구성
- 데이터 보호 및 재해복구
- 보안
- AWS DevOps
  - CI/CD 지속적 통합, 지속적 배포 환경
  - Source :arrow_right: Build :arrow_right: Test :arrow_right: Production

### 프로젝트 추진 개요 및 범위

- AP의 디지털 영업 플랫폼 구축 과제의 복잡한 특성을 고려, 클라우드 인프라 구축 및 기술 지원
- 기술 지원

### Cloud Infra 주요 적용 기술 부문

- 각 계정 VPC Subnet
- Share VPC Subnet
- AZ-A/AZ-C, IGW, Subnet Tier
- 내부 통신
  - 각각의 계정들
- Networking, Compute, Storage, Database

### AP 아키텍쳐 개요 부문

- Account: 개발, 검증, 운영개발, 운영검증, 운영 환경의 계정과 Biling 주체가 다른 계열사 계정, 공통 서비스 배치를 위한 Share 계정 분리 구성
- 1 Account, 1 VPS
- Hybrid IDC
- 보안

### 주요 적용 및 사례

- Etude
- Aritaum: 하이브리드 형태(DB가 송도에 존재)
  - WAS만 클라우드로 구현

## AP Legacy 환경 Migration

### Cloud Migration 방안

Cloud Adoption Framwork 기반 업무 중요도 및 난이도에 따라 On-Premise 환경을 Migration을 위해 Workload 분석, 전환 전략, 전환 방안 등 단계별 수립

이관 패턴 분석

Lift & Shift

거버넌스, 자동화, CI/CD 구성 -> Lift & Shift로 App 변경 최소화, Web/WAS Test

자동화, 배포

표준 리소스 및 운영 시간

RI: 환경 구성 시 개발/검증의 비사용 시간을 설정하여 자동으로 stop/start 할 수 있도록 -> 상시 동작

### Cloud 최적 활용 제안

최적화 작업을 반복 수행하여 클라우드 사용에 대한 인프라 비용 최적화

AWS 내 개발용 인스턴스(DEV/STG)들에 대한 스케줄러 적용을 통해 비업무 시간동안 발생하는 유휴(야간) 지원에 대한 사용 비용 최적화

분기별 AWS 패턴 사용 절감

AutoSpot: 비용효율적인 Spot Instance의 사용성을 높이고 적용 대상 서비스에 대한 인프라 사용 비용 최적화

Well - Architected Review 프로그램 제공

- 보안, 안정성, 성능 효율성, 비용 최적화, 운영 우수성 측면의 검토 결과 제공